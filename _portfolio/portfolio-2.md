---
title: "Unsupervised Speaker Cue Usage Detection in Public Speaking Videos"
excerpt: "Project to quantify non-verbal cue usage into 3 categories, to be used as a higher level feature. Published in BMVC VIBE 2018.<br/><img src='/images/bmvc.png'>"
collection: portfolio
---

Part of an ongoing project with the Multimodal Perception Lab to categorize public speakers by style. We focused on the subproblem of quantising non-verbal cue usage into 3 different categories that can be a part of a richer feature set for characterising style. It can also be used for getting better insight into studies regarding public speaking. Our results were published in the VIBE workshop part of the BMVC 2018 Conference.

You can find the code [here.](https://github.com/anshul-gupta24/Unsupervised-Speaker-Cue-Usage)
